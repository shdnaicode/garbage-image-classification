{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Garbage Classification Model"
      ],
      "metadata": {
        "id": "NGSuK05ZH6Ow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Python Dependencies/Libraries"
      ],
      "metadata": {
        "id": "nm-mJtTXIFLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "MQwFan3dH3LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Move PyTorch to use Apple Silicon CPU if available"
      ],
      "metadata": {
        "id": "Nf-uiPNvImI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "uQHbEXH6IBNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing, resize all images to 224x224 pixels"
      ],
      "metadata": {
        "id": "-OWoMXYFIrRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "rs604RzAIk6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare full_data for dataset to 'data' folders"
      ],
      "metadata": {
        "id": "zq_74enDJVWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_data = datasets.ImageFolder('data', transform=transform)"
      ],
      "metadata": {
        "id": "_7xToxxsJI6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Test/Validate Split"
      ],
      "metadata": {
        "id": "kQ0jcEYVJJvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(full_data))\n",
        "val_size = int(0.15 * len(full_data))\n",
        "test_size = len(full_data) - train_size - val_size\n",
        "\n",
        "train_data, val_data, test_data = random_split(full_data, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32)\n",
        "test_loader = DataLoader(test_data, batch_size=32)\n",
        "\n",
        "num_classes = len(full_data.classes)"
      ],
      "metadata": {
        "id": "AS06D56dJPrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RestNet-18 Model for analzying and training images classification"
      ],
      "metadata": {
        "id": "Ga84k10bJejU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "EpQrdODGJTW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class weights function to balance images between dataset"
      ],
      "metadata": {
        "id": "34dXsf31JqBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(full_data.targets),\n",
        "    y=np.array(full_data.targets)\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "e4M50DMHJwp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start 6 epoches, declare all values to 0"
      ],
      "metadata": {
        "id": "rwqaKxgNJxup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 6\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "val_precisions = []\n",
        "val_recalls = []\n",
        "val_f1s = []"
      ],
      "metadata": {
        "id": "35FgZcapJ6LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training model with epoch vs loss function"
      ],
      "metadata": {
        "id": "pIEKIS1MKBDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = 100 * correct / total\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    val_preds = []\n",
        "    val_labels_list = []"
      ],
      "metadata": {
        "id": "JS6sXS8fKDwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting graph for loss over epoches, and accuracy over epoches"
      ],
      "metadata": {
        "id": "3cD3bgkMKG4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "            val_preds.extend(predicted.cpu().numpy())\n",
        "            val_labels_list.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "IsixNoqIKLZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to calculate the loss, correct, and total from epoch function"
      ],
      "metadata": {
        "id": "EMzVsQqeKbKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " val_loss /= len(val_loader)\n",
        "    val_acc = 100 * val_correct / val_total\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    val_precision = precision_score(val_labels_list, val_preds, average='macro')\n",
        "    val_recall = recall_score(val_labels_list, val_preds, average='macro')\n",
        "    val_f1 = f1_score(val_labels_list, val_preds, average='macro')\n",
        "\n",
        "    val_precisions.append(val_precision)\n",
        "    val_recalls.append(val_recall)\n",
        "    val_f1s.append(val_f1)\n",
        "\n",
        "print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}% | Val F1: {val_f1:.2f}\")\n"
      ],
      "metadata": {
        "id": "lzmU6IEvKZyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the graph set all prediction and labels to 0"
      ],
      "metadata": {
        "id": "ahJCVNzvKluz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "85a3EFKGKfyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Confusion Matrix, Precision, Recall, and F1-Score over epoch function"
      ],
      "metadata": {
        "id": "ufa1gHPqKvkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=full_data.classes))\n",
        "\n",
        "test_precision = precision_score(all_labels, all_preds, average='macro')\n",
        "test_recall = recall_score(all_labels, all_preds, average='macro')\n",
        "test_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall:    {test_recall:.4f}\")\n",
        "print(f\"Test F1 Score:  {test_f1:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=full_data.classes,\n",
        "            yticklabels=full_data.classes)\n",
        "plt.title(\"Confusion Matrix (Test Set)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, epochs + 1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, epochs + 1), val_losses, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, epochs + 1), train_accuracies, label='Train Acc')\n",
        "plt.plot(range(1, epochs + 1), val_accuracies, label='Val Acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(range(1, epochs + 1), val_precisions, label='Validation Precision', marker='o', color='orange')\n",
        "plt.plot(range(1, epochs + 1), val_recalls, label='Validation Recall', marker='s', color='green')\n",
        "plt.plot(range(1, epochs + 1), val_f1s, label='Validation F1 Score', marker='^', color='red')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Validation Precision, Recall, and F1 Score Over Epochs')\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hy7g-5f4LILO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save PyTorch model files"
      ],
      "metadata": {
        "id": "Nv6zWBM4LNyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'waste_classifier.pth')"
      ],
      "metadata": {
        "id": "vFn2eQ6ELR4H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}